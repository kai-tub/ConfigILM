{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised Vision Pre-training\n",
    "\n",
    "The framework allows to pre-train vision models in supervised fashion using classification datasets.\n",
    "For this example usage we will be using the [`BigEarthNet DataModule`](extra/bigearthnet.ipynb) inside a [`pytorch lightning`](https://pytorch-lightning.readthedocs.io/en/stable/) trainer. The network will be integrated into a [`LightningModule`](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html) to release us from writing training loop etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we start by importing the basics we need from `torch` and `pytorch_lightning` that are needed to set up the `LightningModule`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# remove-output\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from configvlm import ConfigVLM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch Lightning Module\n",
    "The `Module` we use to encapsulate the model divides the usual loop into functions that are called internally by `pytorch_lightning`. The necessary functions are just `training_step` and `configure_optimizer`, but to have a fully functional script, we add the validation and test steps as well as evaluation of the validation and test results. All `_step` functions are working on a single batch while `_epoch_end` functions are called after all batches are used and are passed a list of all return values of their respective `_step` functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class LitVQAEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: ConfigVLM.VLMConfiguration,\n",
    "        lr: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.config = config\n",
    "        self.model = ConfigVLM.ConfigVLM(config)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(x_hat, y)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "        return optimizer\n",
    "\n",
    "    # ============== NON-MANDATORY-FUNCTION ===============\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(x_hat, y)\n",
    "        return {\"loss\": loss, \"outputs\": x_hat, \"labels\": y}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"val/loss\", avg_loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(x_hat, y)\n",
    "        return {\"loss\": loss, \"outputs\": x_hat, \"labels\": y}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"test/loss\", avg_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuring\n",
    "Now that we have our model, we will use the `pytorch_lightning.Trainer` to run our loops. Results are logged to `tensorboard`.\n",
    "\n",
    "We start by importing some callbacks used during training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from configvlm.ConfigVLM import VLMConfiguration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "as well as defining our hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "seed = 42\n",
    "number_of_channels = 12\n",
    "image_size = 120\n",
    "epochs = 4\n",
    "lr = 5e-4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we create the configuration for usage in model creation later and the logger."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# remove-output\n",
    "# seed for pytorch, numpy, python.random, Dataloader workers, spawned subprocesses\n",
    "pl.seed_everything(seed, workers=True)\n",
    "\n",
    "model_config = VLMConfiguration(\n",
    "    timm_model_name=model_name,\n",
    "    hf_model_name=None,\n",
    "    classes=19,\n",
    "    image_size=image_size,\n",
    "    channels=number_of_channels,\n",
    "    network_type=ConfigVLM.VLMType.VISION_CLASSIFICATION\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"./tb_logs\",\n",
    "    name=\"Classification Test Model\",\n",
    "    version=\"testversion\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We log the hyperparameters and create a [Trainer](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# remove-output\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    accelerator=\"auto\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "logger.log_hyperparams({\n",
    "    \"Model Name\": \"Classification Test Model\",\n",
    "    \"Seed\": seed,\n",
    "    \"Epochs\": epochs,\n",
    "    \"Channels\": number_of_channels,\n",
    "    \"Image Size\": image_size,\n",
    "    \"GPU\": torch.cuda.get_device_name() if torch.cuda.is_available() else \"-\",\n",
    "    \"Learning Rate\": lr,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Model + Dataset\n",
    "Finally, we create the model defined above and our datamodule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# remove-input\n",
    "# remove-output\n",
    "import pathlib\n",
    "my_data_path = str(pathlib.Path(\"\").resolve().parent.joinpath(\"configvlm\").joinpath(\"extra\").joinpath(\"mock_data\").resolve(strict=True))\n",
    "# set precision on Ampere cards to bfloat16\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader using 4 workers\n"
     ]
    }
   ],
   "source": [
    "# remove-output\n",
    "from configvlm.extra.BEN_DataModule_LMDB_Encoder import BENDataModule\n",
    "model = LitVQAEncoder(config=model_config, lr=lr)\n",
    "dm = BENDataModule(\n",
    "    data_dir=my_data_path,\n",
    "    img_size=(number_of_channels, image_size, image_size),\n",
    "    num_workers_dataloader=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running\n",
    "Now we just have to call the `fit()` and optionally the `test()` functions.\n",
    "\n",
    ":::{note}\n",
    "These calls generate quite a bit of output depending on the number of batches and epochs. The output is removed for readability.\n",
    ":::"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | ConfigVLM | 11.2 M\n",
      "------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.858    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12:21:51) Datamodule setup called\n",
      "Loading BEN data for train...\n",
      "    25 patches indexed\n",
      "    25 filtered patches indexed\n",
      "Loading BEN data for val...\n",
      "    25 patches indexed\n",
      "    25 filtered patches indexed\n",
      "setup took 0.00 seconds\n",
      "  Total training samples:       25  Total validation samples:       25\n",
      "Epoch 0:  50%|█████     | 2/4 [00:00<00:00,  7.77it/s, loss=0.705, v_num=sion]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 0:  75%|███████▌  | 3/4 [00:00<00:00,  6.14it/s, loss=0.705, v_num=sion]\n",
      "Epoch 0: 100%|██████████| 4/4 [00:00<00:00,  8.03it/s, loss=0.705, v_num=sion]\n",
      "Epoch 1:  50%|█████     | 2/4 [00:00<00:00,  7.11it/s, loss=0.666, v_num=sion]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3/4 [00:00<00:00,  6.04it/s, loss=0.666, v_num=sion]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:00<00:00,  7.89it/s, loss=0.666, v_num=sion]\n",
      "Epoch 2:  50%|█████     | 2/4 [00:00<00:00,  6.95it/s, loss=0.635, v_num=sion]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 3/4 [00:00<00:00,  5.97it/s, loss=0.635, v_num=sion]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00,  7.77it/s, loss=0.635, v_num=sion]\n",
      "Epoch 3:  50%|█████     | 2/4 [00:00<00:00,  7.27it/s, loss=0.608, v_num=sion]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 3/4 [00:00<00:00,  6.18it/s, loss=0.608, v_num=sion]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00,  8.04it/s, loss=0.608, v_num=sion]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00,  8.01it/s, loss=0.608, v_num=sion]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00,  5.77it/s, loss=0.608, v_num=sion]\n"
     ]
    }
   ],
   "source": [
    "# remove-output\n",
    "trainer.fit(model, datamodule=dm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12:21:54) Datamodule setup called\n",
      "Loading BEN data for test...\n",
      "    25 patches indexed\n",
      "    25 filtered patches indexed\n",
      "setup took 0.00 seconds\n",
      "  Total test samples:       25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 98.35it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001B[36m \u001B[0m\u001B[36m        test/loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.6129004955291748    \u001B[0m\u001B[35m \u001B[0m│\n└───────────────────────────┴───────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6129004955291748     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[{'test/loss': 0.6129004955291748}]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove-output\n",
    "trainer.test(model, datamodule=dm)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
